import streamlit as st
import os
import sys
import time
import re
import json
import concurrent.futures
from datetime import datetime
import shutil

# æ·»åŠ  src åˆ°è·¯å¾„ä»¥ä¾¿å¯¼å…¥æ¨¡å—
sys.path.append(os.path.dirname(__file__))

from main import DesignWorkflow
import config
import md_parser

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="AI è®¾è®¡å·¥ä½œæµ (AI Design Workflow)",
    page_icon="ğŸ¨",
    layout="wide",
    initial_sidebar_state="expanded",
)

# è‡ªå®šä¹‰ CSS
st.markdown(
    """
<style>
    .report-content {
        background-color: #ffffff;
        padding: 30px;
        border-radius: 12px;
        box-shadow: 0 4px 20px rgba(0,0,0,0.08);
        border: none;
        font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;
        color: #1a1a1a; /* å¼ºåˆ¶å­—ä½“é¢œè‰²ä¸ºæ·±è‰² */
    }
    .stButton>button {
        border-radius: 8px;
        height: 3rem;
        font-weight: 600;
        transition: all 0.3s ease;
        color: #1a1a1a; /* ç¡®ä¿æŒ‰é’®æ–‡å­—é¢œè‰²ä¸ºæ·±è‰² */
        background-color: #ffffff; /* ç¡®ä¿èƒŒæ™¯ä¸ºç™½è‰² */
        border: 1px solid #e0e0e0;
    }
    /* é’ˆå¯¹ markdown å®¹å™¨å†…çš„æ‰€æœ‰æ–‡æœ¬å¼ºåˆ¶æ·±è‰² */
    .stMarkdown p, .stMarkdown h1, .stMarkdown h2, .stMarkdown h3, .stMarkdown li {
        color: #1a1a1a !important;
    }
    /* ä¿®å¤ Tab æ ‡ç­¾é¡µå†…çš„æ–‡æœ¬é¢œè‰² */
    .stTabs [data-baseweb="tab"] {
         color: #1a1a1a !important;
    }
    .stButton>button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.15);
    }
    h1, h2, h3 {
        font-family: 'SF Pro Display', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
        color: #1a1a1a;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
        border-radius: 8px;
        padding: 4px;
        background-color: #f1f5f9;
    }
    .stTabs [data-baseweb="tab"] {
        border-radius: 6px;
        padding: 8px 16px;
        background-color: transparent;
        border: none;
    }
    .stTabs [aria-selected="true"] {
        background-color: white;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .sidebar-content {
        padding: 1rem;
        border-radius: 8px;
        background: #f8fafc;
        margin-bottom: 1rem;
    }
</style>
""",
    unsafe_allow_html=True,
)


class StreamlitLogger:
    """
    é€‚é…å™¨ï¼šå°† DesignWorkflow çš„æ—¥å¿—é‡å®šå‘åˆ° Streamlit ç•Œé¢
    """

    def __init__(self, log_container):
        self.log_container = log_container
        self.logs = []

    def log(self, message):
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] {message}"
        self.logs.append(log_entry)

        # å®æ—¶æ›´æ–° UI
        if self.log_container:
            with self.log_container:
                # åªæ˜¾ç¤ºæœ€è¿‘çš„ 10 æ¡æ—¥å¿—
                log_text = "\n".join(self.logs[-10:])
                st.code(log_text, language="text")


class WebDesignWorkflow(DesignWorkflow):
    """
    ç»§æ‰¿ DesignWorkflowï¼Œé€‚é… Web ç«¯äº¤äº’
    """

    def __init__(self, output_dir, custom_config, logger):
        super().__init__(output_dir, custom_config)
        self.logger = logger
        # å¤ç”¨çˆ¶ç±»çš„ generated_images

    def log(self, message):
        self.logger.log(message)

    # é‡å†™ step_image_generation ä»¥æ”¯æŒ Streamlit è¿›åº¦æ¡
    def step_image_generation(self, prompts_list):
        if not prompts_list:
            self.log("    âš ï¸ æœªæ£€æµ‹åˆ°æœ‰æ•ˆ Promptï¼Œè·³è¿‡ç»˜å›¾ã€‚")
            return

        clean_prompts = [p.get("prompt", "") for p in prompts_list if p.get("prompt")]
        if not clean_prompts:
            return

        total = len(clean_prompts)
        self.log(f"    - å‡†å¤‡å¹¶è¡Œç”Ÿæˆ {total} å¼ æ–¹æ¡ˆå›¾...")

        progress_bar = st.progress(0, text="æ­£åœ¨ç”Ÿæˆå›¾ç‰‡...")
        completed = 0

        def generate_single(p):
            try:
                return self.image_gen.generate_image(p, self.output_dir)
            except Exception as e:
                self.log(f"Error generating image: {e}")
                return None

        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
            futures = [executor.submit(generate_single, p) for p in clean_prompts]
            for future in concurrent.futures.as_completed(futures):
                img_path = future.result()
                if img_path:
                    self.log(f"      -> å›¾ç‰‡å·²ä¿å­˜: {os.path.basename(img_path)}")
                    self.generated_images.append(img_path)

                completed += 1
                progress_bar.progress(
                    completed / total, text=f"æ­£åœ¨ç”Ÿæˆç¬¬ {completed}/{total} å¼ å›¾ç‰‡..."
                )

        progress_bar.empty()


def init_session_state():
    defaults = {
        "project_name": "Polaroid_Bag_Design",
        "brief": "åšä¸€æ¬¾æ‹ç«‹å¾—ç›¸æœºåŒ…ï¼Œéœ€è¦å‚è€ƒå¸‚åœºä¸­é«˜ç«¯å“ç‰Œçš„å¥³æ€§åŒ…åŒ…å»ç»“åˆè®¾è®¡ä¸€äº›ç›¸æœºåŒ…",
        "market_analysis": "",
        "visual_research": "",
        "design_proposals": "",
        "design_prompts": [],
        "generated_images": [],
        "full_report": "",
        "logs": [],
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v


def load_history_project(project_name):
    """
    åŠ è½½å†å²é¡¹ç›®æ•°æ®åˆ° Session State
    """
    root_dir = os.path.dirname(os.path.dirname(__file__))
    project_dir = os.path.join(root_dir, "projects", project_name)

    if not os.path.exists(project_dir):
        st.error(f"é¡¹ç›® {project_name} ä¸å­˜åœ¨")
        return

    st.session_state.project_name = project_name

    # å°è¯•åŠ è½½å„ä¸ª Markdown æ–‡ä»¶
    def read_file(fname):
        path = os.path.join(project_dir, fname)
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                return f.read()
        return ""

    st.session_state.market_analysis = read_file("1_Market_Analysis.md")
    st.session_state.visual_research = read_file("2_Visual_Research.md")
    st.session_state.design_proposals = read_file("3_Design_Proposals.md")
    st.session_state.full_report = read_file("Full_Design_Report.md")

    # å°è¯•åŠ è½½å›¾ç‰‡
    # æ‰«æç›®å½•ä¸‹æ‰€æœ‰ jpg/png
    images = []
    for f in os.listdir(project_dir):
        if f.lower().endswith((".jpg", ".jpeg", ".png")):
            images.append(os.path.join(project_dir, f))

    # æŒ‰æ—¶é—´æ’åºå›¾ç‰‡ï¼ˆå¦‚æœæ–‡ä»¶ååŒ…å«æ—¶é—´æˆ³ï¼‰
    images.sort(key=lambda x: os.path.getmtime(x), reverse=True)
    # ä½¿ç”¨ç»å¯¹è·¯å¾„
    st.session_state.generated_images = [os.path.abspath(p) for p in images]

    st.success(f"å·²åŠ è½½é¡¹ç›®: {project_name}")


def get_workflow(project_dir, model_name, log_container=None):
    root_dir = os.path.dirname(os.path.dirname(__file__))
    custom_config = {
        "OPENAI_API_KEY": config.OPENAI_API_KEY,
        "OPENAI_BASE_URL": config.OPENAI_BASE_URL,
        "DEFAULT_MODEL": model_name,
        "prompts": md_parser.parse_config_md(os.path.join(root_dir, "CONFIG.md")).get(
            "prompts", {}
        ),
    }
    logger = StreamlitLogger(log_container)
    return WebDesignWorkflow(project_dir, custom_config, logger)


def main():
    st.title("ğŸ¨ AI è®¾è®¡å·¥ä½œæµ (AI Design Workflow)")
    st.markdown("åŸºäº Gemini å’Œ Jimeng çš„å…¨è‡ªåŠ¨è®¾è®¡åŠ©æ‰‹")

    init_session_state()

    # --- ä¾§è¾¹æ é…ç½® ---
    with st.sidebar:
        # 1. å†å²é¡¹ç›® (History)
        st.header("ğŸ“‚ å†å²é¡¹ç›®")

        # æ‰«æ projects æ–‡ä»¶å¤¹
        root_dir = os.path.dirname(os.path.dirname(__file__))
        projects_dir = os.path.join(root_dir, "projects")

        existing_projects = []
        if os.path.exists(projects_dir):
            existing_projects = [
                d
                for d in os.listdir(projects_dir)
                if os.path.isdir(os.path.join(projects_dir, d))
            ]
            # æŒ‰ä¿®æ”¹æ—¶é—´å€’åºæ’åˆ—
            existing_projects.sort(
                key=lambda x: os.path.getmtime(os.path.join(projects_dir, x)),
                reverse=True,
            )

        selected_project = st.selectbox(
            "é€‰æ‹©å†å²é¡¹ç›®åŠ è½½", ["-- æ–°å»ºé¡¹ç›® --"] + existing_projects, index=0
        )

        if selected_project != "-- æ–°å»ºé¡¹ç›® --":
            if st.button("ğŸ“‚ åŠ è½½é€‰ä¸­é¡¹ç›®"):
                load_history_project(selected_project)

        st.divider()

        st.header("âš™ï¸ ç³»ç»Ÿé…ç½®")

        model_options = [
            "gemini-2.0-flash-exp",
            "gemini-1.5-pro",
            "gemini-1.5-flash",
            "gemini-2.5-flash",
        ]
        model_name = st.selectbox("æ¨¡å‹é€‰æ‹© (Gemini)", model_options, index=0)

        st.divider()
        with st.expander("ğŸ“š æŸ¥çœ‹çŸ¥è¯†åº“"):
            kb_path = os.path.join(
                os.path.dirname(os.path.dirname(__file__)), "KNOWLEDGE.md"
            )
            if os.path.exists(kb_path):
                with open(kb_path, "r", encoding="utf-8") as f:
                    st.text(f.read())

    # --- ä¸»ç•Œé¢ ---
    col1, col2 = st.columns([3, 1])
    with col1:
        st.session_state.project_name = st.text_input(
            "é¡¹ç›®åç§°", value=st.session_state.project_name
        )

    st.session_state.brief = st.text_area(
        "âœï¸ è¯·è¾“å…¥è®¾è®¡éœ€æ±‚", height=100, value=st.session_state.brief
    )

    # å›¾ç‰‡æ•°é‡è®¾ç½®
    with st.expander("âš™ï¸ ç”Ÿæˆè®¾ç½®", expanded=False):
        col_img1, col_img2 = st.columns(2)
        with col_img1:
            image_count = st.number_input(
                "æ–¹æ¡ˆå›¾ç‰‡æ•°é‡", min_value=1, max_value=12, value=4, step=1
            )
        with col_img2:
            persona = st.text_input(
                "è§’è‰²è§†è§’ï¼ˆå¯é€‰ï¼‰", placeholder="å¦‚ï¼šå·¥ä¸šè®¾è®¡å¸ˆã€æ—¶å°šåšä¸»..."
            )

    # å…¨å±€è¿è¡ŒæŒ‰é’®
    if st.button("ğŸš€ ä¸€é”®ç”Ÿæˆå…¨æµç¨‹", type="primary", use_container_width=True):
        st.session_state.logs = []  # æ¸…ç©ºæ—§æ—¥å¿—

        root_dir = os.path.dirname(os.path.dirname(__file__))
        project_dir = os.path.join(root_dir, "projects", st.session_state.project_name)

        st.subheader("ğŸ“ è¿è¡Œæ—¥å¿—")
        log_container = st.empty()
        wf = get_workflow(project_dir, model_name, log_container)

        with st.spinner("AI æ­£åœ¨å…¨é€Ÿè¿è½¬ä¸­..."):
            # Step 1
            wf.log("å¼€å§‹å¸‚åœºåˆ†æ...")
            m_analysis, _ = wf.step_market_analysis(st.session_state.brief)
            st.session_state.market_analysis = m_analysis
            wf._save_intermediate("1_Market_Analysis.md", m_analysis)

            # Step 2
            wf.log("å¼€å§‹è§†è§‰è°ƒç ”...")
            v_research, _ = wf.step_visual_research(st.session_state.brief, m_analysis)
            st.session_state.visual_research = v_research
            wf._save_intermediate("2_Visual_Research.md", v_research)

            # Step 3
            wf.log("å¼€å§‹æ–¹æ¡ˆè®¾è®¡...")
            d_proposals, d_prompts = wf.step_design_generation(
                st.session_state.brief,
                m_analysis,
                v_research,
                image_count=image_count,
                persona=persona,
            )
            st.session_state.design_proposals = d_proposals
            st.session_state.design_prompts = d_prompts
            wf._save_intermediate("3_Design_Proposals.md", d_proposals)

            # Step 4
            wf.log("å¼€å§‹ç”Ÿæˆæœ€ç»ˆæ•ˆæœå›¾...")
            wf.step_image_generation(d_prompts)
            st.session_state.generated_images = wf.generated_images  # æ›´æ–°å›¾ç‰‡åˆ—è¡¨

            # Step 5
            report_path = wf._save_report(
                st.session_state.brief, m_analysis, v_research, d_proposals
            )
            st.session_state.full_report = f"æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}"

        st.success("å…¨æµç¨‹ä»»åŠ¡å®Œæˆï¼")

    st.divider()

    # --- æ¨¡å—åŒ–å±•ç¤ºä¸æ“ä½œ ---
    tab1, tab2, tab3, tab4, tab5 = st.tabs(
        ["ğŸ“ˆ å¸‚åœºåˆ†æ", "ğŸ¨ è§†è§‰è°ƒç ”", "ğŸ’¡ æ–¹æ¡ˆè®¾è®¡", "ğŸ–¼ï¸ æœ€ç»ˆå›¾åº“", "ğŸ“‹ å®Œæ•´æŠ¥å‘Š"]
    )

    root_dir = os.path.dirname(os.path.dirname(__file__))
    project_dir = os.path.join(root_dir, "projects", st.session_state.project_name)

    # Tab 1: å¸‚åœºåˆ†æ
    with tab1:
        col_t1_1, col_t1_2 = st.columns([4, 1])
        with col_t1_2:
            st.markdown("### ğŸ“ˆ å¸‚åœºåˆ†æ")
            if st.button("ğŸ”„ é‡æ–°ç”Ÿæˆ", type="secondary", use_container_width=True):
                with st.spinner("ğŸ” æ­£åœ¨åˆ†æå¸‚åœºè¶‹åŠ¿..."):
                    wf = get_workflow(project_dir, model_name)
                    res, _ = wf.step_market_analysis(st.session_state.brief)
                    st.session_state.market_analysis = res
                    wf._save_intermediate("1_Market_Analysis.md", res)
                    st.rerun()

        if st.session_state.market_analysis:
            st.markdown(st.session_state.market_analysis)
        else:
            st.info("ğŸ“Š æš‚æ— å¸‚åœºåˆ†æç»“æœï¼Œç‚¹å‡»ä¸Šæ–¹æŒ‰é’®ç”Ÿæˆ")

    # Tab 2: è§†è§‰è°ƒç ”
    with tab2:
        col_t2_1, col_t2_2 = st.columns([4, 1])
        with col_t2_2:
            st.markdown("### ğŸ¨ è§†è§‰è°ƒç ”")
            if st.button("ğŸ”„ é‡æ–°ç”Ÿæˆ", type="secondary", use_container_width=True):
                if not st.session_state.market_analysis:
                    st.error("âš ï¸ è¯·å…ˆç”Ÿæˆå¸‚åœºåˆ†ææŠ¥å‘Š")
                else:
                    with st.spinner("ğŸ¨ æ­£åœ¨å¯»æ‰¾è§†è§‰å‚è€ƒ..."):
                        wf = get_workflow(project_dir, model_name)
                        res, _ = wf.step_visual_research(
                            st.session_state.brief, st.session_state.market_analysis
                        )
                        st.session_state.visual_research = res
                        wf._save_intermediate("2_Visual_Research.md", res)
                        st.rerun()

        if st.session_state.visual_research:
            st.markdown(st.session_state.visual_research)
        else:
            st.info("ğŸ¨ æš‚æ— è§†è§‰è°ƒç ”ç»“æœï¼Œè¯·å…ˆå®Œæˆå¸‚åœºåˆ†æåç‚¹å‡»ç”Ÿæˆ")

    # Tab 3: æ–¹æ¡ˆè®¾è®¡
    with tab3:
        col_t3_1, col_t3_2 = st.columns([4, 1])
        with col_t3_2:
            st.markdown("### ğŸ’¡ æ–¹æ¡ˆè®¾è®¡")
            if st.button("ğŸ”„ é‡æ–°ç”Ÿæˆ", type="secondary", use_container_width=True):
                if not st.session_state.visual_research:
                    st.error("âš ï¸ è¯·å…ˆç”Ÿæˆè§†è§‰è°ƒç ”æŠ¥å‘Š")
                else:
                    with st.spinner("ğŸ’¡ æ­£åœ¨æ„æ€è®¾è®¡æ–¹æ¡ˆ..."):
                        wf = get_workflow(project_dir, model_name)
                        res, prompts = wf.step_design_generation(
                            st.session_state.brief,
                            st.session_state.market_analysis,
                            st.session_state.visual_research,
                        )
                        st.session_state.design_proposals = res
                        st.session_state.design_prompts = prompts
                        wf._save_intermediate("3_Design_Proposals.md", res)
                        st.rerun()

        # å›¾ç‰‡æ•°é‡è®¾ç½®
        with st.expander("âš™ï¸ æ–¹æ¡ˆè®¾ç½®", expanded=False):
            image_count = st.number_input(
                "ç”Ÿæˆæ–¹æ¡ˆæ•°é‡", min_value=1, max_value=12, value=4, step=1
            )
            persona = st.text_input(
                "è§’è‰²è§†è§’ï¼ˆå¯é€‰ï¼‰", placeholder="å¦‚ï¼šå·¥ä¸šè®¾è®¡å¸ˆã€æ—¶å°šåšä¸»..."
            )

        # å±•ç¤ºæ–¹æ¡ˆå†…å®¹
        if st.session_state.design_proposals:
            try:
                # å°è¯•è§£æJSONæ ¼å¼çš„è®¾è®¡æ–¹æ¡ˆ
                proposals_data = json.loads(st.session_state.design_proposals)
                if isinstance(proposals_data, dict) and "prompts" in proposals_data:
                    prompts_list = proposals_data["prompts"]

                    st.markdown("### ğŸ’¡ è®¾è®¡æ–¹æ¡ˆ")

                    for idx, item in enumerate(prompts_list):
                        with st.container():
                            c1, c2 = st.columns([1, 2])
                            with c1:
                                scheme = item.get("scheme", f"æ–¹æ¡ˆ {idx + 1}")
                                st.markdown(f"#### {scheme}")

                                # å¦‚æœæœ‰å›¾ç‰‡è·¯å¾„ï¼Œæ˜¾ç¤ºå›¾ç‰‡
                                if "image_path" in item:
                                    img_path = item["image_path"]
                                    if os.path.exists(img_path):
                                        st.image(img_path, use_container_width=True)
                                    elif os.path.exists(
                                        os.path.join(
                                            project_dir, os.path.basename(img_path)
                                        )
                                    ):
                                        st.image(
                                            os.path.join(
                                                project_dir, os.path.basename(img_path)
                                            ),
                                            use_container_width=True,
                                        )

                            with c2:
                                inspiration = item.get("inspiration", "")
                                if inspiration:
                                    st.markdown(f"**ğŸ¯ åˆ›æ„æºæ³‰**: {inspiration}")

                                description = item.get("description", "")
                                if description:
                                    st.markdown(f"**ğŸ“ è®¾è®¡æè¿°**: {description}")

                                prompt = item.get("prompt", "")
                                if prompt:
                                    st.code(prompt, language="text")

                        st.divider()

                    # ä¿å­˜promptsåˆ°session stateç”¨äºå›¾ç‰‡ç”Ÿæˆ
                    if prompts_list != st.session_state.design_prompts:
                        st.session_state.design_prompts = prompts_list

                else:
                    st.markdown(st.session_state.design_proposals)
            except json.JSONDecodeError:
                st.markdown(st.session_state.design_proposals)
        else:
            st.markdown("æš‚æ— å†…å®¹ï¼Œè¯·ç‚¹å‡»ç”Ÿæˆã€‚")

        # åœ¨æ–¹æ¡ˆåº•éƒ¨æ·»åŠ è¿½åŠ åŠŸèƒ½
        st.divider()
        st.markdown("### â• è¿½åŠ æ›´å¤šæ–¹æ¡ˆ")
        st.markdown("åŸºäºç°æœ‰è®¾è®¡æ–¹æ¡ˆï¼Œç”Ÿæˆæ›´å¤šå·®å¼‚åŒ–å˜ä½“")

        col_add1, col_add2 = st.columns([1, 3])
        with col_add1:
            add_count = st.number_input(
                "è¿½åŠ æ•°é‡", min_value=1, max_value=8, value=2, step=1, key="add_count"
            )
        with col_add2:
            add_persona = st.text_input(
                "è§’è‰²è§†è§’ï¼ˆå¯é€‰ï¼‰", placeholder="å¦‚ï¼šå·¥ä¸šè®¾è®¡å¸ˆ...", key="add_persona"
            )

        if st.button("ğŸš€ ç”Ÿæˆè¿½åŠ æ–¹æ¡ˆ", type="primary"):
            if not st.session_state.design_proposals:
                st.error("è¯·å…ˆç”Ÿæˆè®¾è®¡æ–¹æ¡ˆï¼")
            else:
                with st.spinner("æ­£åœ¨ç”Ÿæˆè¿½åŠ æ–¹æ¡ˆ..."):
                    try:
                        wf = get_workflow(project_dir, model_name)

                        # å°è¯•è§£æç°æœ‰æ–¹æ¡ˆ
                        try:
                            current_proposals = json.loads(
                                st.session_state.design_proposals
                            )
                            if (
                                isinstance(current_proposals, dict)
                                and "prompts" in current_proposals
                            ):
                                current_prompts = current_proposals["prompts"]
                            else:
                                current_prompts = (
                                    st.session_state.design_prompts
                                    if st.session_state.design_prompts
                                    else []
                                )
                        except:
                            current_prompts = (
                                st.session_state.design_prompts
                                if st.session_state.design_prompts
                                else []
                            )

                        # è°ƒç”¨è¿½åŠ æ–¹æ¡ˆæ¥å£
                        # è¿™é‡Œç›´æ¥è°ƒç”¨æ¨¡å‹ç”Ÿæˆæ–°æ–¹æ¡ˆ
                        add_persona_instruction = (
                            f"ä»¥ã€{add_persona}ã€‘çš„è§†è§’ï¼Œ" if add_persona else ""
                        )

                        from llm_wrapper import LLMService
                        import md_parser as mp

                        root_dir = os.path.dirname(os.path.dirname(__file__))
                        config_path = os.path.join(root_dir, "CONFIG.md")
                        md_config = (
                            mp.parse_config_md(config_path)
                            if os.path.exists(config_path)
                            else {}
                        )
                        prompts_cfg = md_config.get("prompts", {})

                        default_prompt = """
                        åŸºäºä»¥ä¸‹è®¾è®¡æ–¹æ¡ˆï¼š
                        {design_proposals}
                        
                        è¯·{add_persona_instruction}å†æ„æ€ {count} ä¸ªæ–°çš„ã€æœ‰å·®å¼‚åŒ–çš„è®¾è®¡æ–¹æ¡ˆå˜ä½“ï¼Œå¹¶æä¾›å¯¹åº”çš„ç»˜å›¾ Promptã€‚
                        è¯·åªè¾“å‡º JSON æ ¼å¼ï¼ŒåŒ…å« `prompts` åˆ—è¡¨ã€‚
                        """

                        prompt_template = prompts_cfg.get(
                            "variant_generator", default_prompt
                        )

                        # å‡†å¤‡ä¸Šä¸‹æ–‡
                        dp_content = (
                            st.session_state.design_proposals[:3000] + "..."
                            if len(st.session_state.design_proposals) > 3000
                            else st.session_state.design_proposals
                        )

                        prompt = prompt_template.format(
                            design_proposals=dp_content,
                            add_persona_instruction=add_persona_instruction,
                            count=add_count,
                        )

                        llm = LLMService(
                            api_key=config.OPENAI_API_KEY,
                            base_url=config.OPENAI_BASE_URL,
                        )

                        messages = [{"role": "user", "content": prompt}]
                        response = llm.chat_completion(messages, model=model_name)

                        # è§£ææ–°æ–¹æ¡ˆ
                        _, new_prompts = wf._process_llm_json_response(response)

                        if new_prompts:
                            # ç”Ÿæˆæ–°æ–¹æ¡ˆå›¾ç‰‡
                            wf.step_image_generation(new_prompts)

                            # åˆå¹¶åˆ°ç°æœ‰æ–¹æ¡ˆ
                            try:
                                current_data = json.loads(
                                    st.session_state.design_proposals
                                )
                                if (
                                    isinstance(current_data, dict)
                                    and "prompts" in current_data
                                ):
                                    current_data["prompts"].extend(new_prompts)
                                    st.session_state.design_proposals = json.dumps(
                                        current_data, ensure_ascii=False
                                    )
                                    st.session_state.design_prompts = current_data[
                                        "prompts"
                                    ]
                                else:
                                    # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œè¿½åŠ åˆ°æœ«å°¾
                                    st.session_state.design_proposals += (
                                        "\n\n### è¿½åŠ æ–¹æ¡ˆ\n"
                                    )
                                    for i, p in enumerate(new_prompts):
                                        st.session_state.design_proposals += f"\n#### æ–¹æ¡ˆ {len(st.session_state.design_prompts) + i + 1}\n"
                                        if p.get("scheme"):
                                            st.session_state.design_proposals += (
                                                f"- åç§°: {p.get('scheme')}\n"
                                            )
                                        if p.get("prompt"):
                                            st.session_state.design_proposals += (
                                                f"- Prompt: {p.get('prompt')}\n"
                                            )
                                    st.session_state.design_prompts.extend(new_prompts)
                            except:
                                st.session_state.design_prompts.extend(new_prompts)

                            # æ›´æ–°ç”Ÿæˆçš„å›¾ç‰‡åˆ—è¡¨
                            st.session_state.generated_images.extend(
                                wf.generated_images
                            )

                            st.success(f"æˆåŠŸç”Ÿæˆ {len(new_prompts)} ä¸ªè¿½åŠ æ–¹æ¡ˆï¼")
                            st.rerun()
                        else:
                            st.error("æœªèƒ½ç”Ÿæˆæœ‰æ•ˆæ–¹æ¡ˆï¼Œè¯·é‡è¯•")

                    except Exception as e:
                        st.error(f"ç”Ÿæˆè¿½åŠ æ–¹æ¡ˆå¤±è´¥: {e}")

    # Tab 4: æœ€ç»ˆå›¾åº“
    with tab4:
        col_t4_1, col_t4_2 = st.columns([4, 1])
        with col_t4_2:
            st.markdown("### ğŸ–¼ï¸ æœ€ç»ˆå›¾åº“")
            if st.button("ğŸ¨ é‡æ–°ç”Ÿæˆå›¾ç‰‡", type="secondary", use_container_width=True):
                if not st.session_state.design_prompts:
                    st.error("âš ï¸ æš‚æ— è®¾è®¡ Promptï¼Œè¯·å…ˆç”Ÿæˆæ–¹æ¡ˆ")
                else:
                    with st.spinner("ğŸ¨ æ­£åœ¨ç»˜åˆ¶æ¦‚å¿µå›¾..."):
                        wf = get_workflow(project_dir, model_name)
                        wf.step_image_generation(st.session_state.design_prompts)
                        st.session_state.generated_images.extend(wf.generated_images)
                        st.rerun()
                        # åˆå¹¶æ–°ç”Ÿæˆçš„å›¾ç‰‡
                        st.session_state.generated_images.extend(wf.generated_images)
                        st.rerun()

        if st.session_state.generated_images:
            cols = st.columns(3)
            for idx, img_path in enumerate(st.session_state.generated_images):
                with cols[idx % 3]:
                    # ç¡®ä¿è·¯å¾„å­˜åœ¨ä¸”æ˜¯ç»å¯¹è·¯å¾„
                    abs_path = os.path.abspath(img_path)
                    if os.path.exists(abs_path):
                        st.image(
                            abs_path, caption=f"Img {idx + 1}", use_container_width=True
                        )

                        # æ·»åŠ ä¸‹è½½æŒ‰é’®
                        with open(abs_path, "rb") as file:
                            btn = st.download_button(
                                label="ğŸ“¥ ä¸‹è½½å›¾ç‰‡",
                                data=file,
                                file_name=os.path.basename(abs_path),
                                mime="image/jpeg",
                                key=f"download_btn_{idx}",
                            )
                    else:
                        st.warning(f"å›¾ç‰‡æ–‡ä»¶æœªæ‰¾åˆ°: {img_path}")
        else:
            st.info("æš‚æ— ç”Ÿæˆçš„å›¾ç‰‡")

    # Tab 5: å®Œæ•´æŠ¥å‘Š
    with tab5:
        if st.button("ğŸ“„ åˆæˆ/åˆ·æ–°å®Œæ•´æŠ¥å‘Š"):
            wf = get_workflow(project_dir, model_name)
            report_path = wf._save_report(
                st.session_state.brief,
                st.session_state.market_analysis,
                st.session_state.visual_research,
                st.session_state.design_proposals,
            )
            st.success(f"æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

            with open(report_path, "r", encoding="utf-8") as f:
                report_content = f.read()
                st.markdown(report_content)
                st.download_button("ğŸ“¥ ä¸‹è½½ Markdown", report_content, "Full_Report.md")


if __name__ == "__main__":
    main()
