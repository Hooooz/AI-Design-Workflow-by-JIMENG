import os
import sys
import time
import re
import json
import concurrent.futures
from datetime import datetime
from typing import Dict, Any, Tuple, List

# Add current directory to path for imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from llm_wrapper import LLMService
from image_gen import ImageGenService
import config
import md_parser


class DesignWorkflowError(Exception):
    """è®¾è®¡å·¥ä½œæµåŸºç¡€å¼‚å¸¸ç±»"""

    def __init__(self, message: str, step: str = None, recoverable: bool = False):
        self.message = message
        self.step = step
        self.recoverable = recoverable
        super().__init__(self.message)


class MarketAnalysisError(DesignWorkflowError):
    """å¸‚åœºåˆ†æé˜¶æ®µé”™è¯¯"""

    def __init__(self, message: str):
        super().__init__(message, step="market_analysis", recoverable=True)


class VisualResearchError(DesignWorkflowError):
    """è§†è§‰ç ”ç©¶é˜¶æ®µé”™è¯¯"""

    def __init__(self, message: str):
        super().__init__(message, step="visual_research", recoverable=True)


class DesignGenerationError(DesignWorkflowError):
    """æ–¹æ¡ˆè®¾è®¡é˜¶æ®µé”™è¯¯"""

    def __init__(self, message: str):
        super().__init__(message, step="design_generation", recoverable=True)


class ImageGenerationError(DesignWorkflowError):
    """å›¾ç‰‡ç”Ÿæˆé˜¶æ®µé”™è¯¯"""

    def __init__(self, message: str):
        super().__init__(message, step="image_generation", recoverable=True)


class DesignWorkflow:
    def __init__(self, output_dir=None, custom_config=None):
        self.custom_config = custom_config or {}
        # ä¼˜å…ˆä½¿ç”¨ custom_config ä¸­çš„ api_key
        api_key = self.custom_config.get("OPENAI_API_KEY")
        base_url = self.custom_config.get("OPENAI_BASE_URL")

        self.llm = LLMService(api_key=api_key, base_url=base_url)

        # åˆå§‹åŒ–ç»˜å›¾æœåŠ¡
        jimeng_script = (
            self.custom_config.get("JIMENG_SERVER_SCRIPT")
            or config.JIMENG_SERVER_SCRIPT
        )
        self.image_gen = ImageGenService(server_script_path=jimeng_script)

        self.history = []
        self.generated_images = []

        self.output_dir = output_dir or config.OUTPUT_DIR
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)

        # è®¾ç½®é»˜è®¤æ¨¡å‹
        self.model = self.custom_config.get("DEFAULT_MODEL", config.DEFAULT_MODEL)

        # åŠ è½½å¤–éƒ¨çŸ¥è¯†åº“
        self.knowledge_base = self._load_knowledge_base()

    def _load_knowledge_base(self):
        """
        åŠ è½½ KNOWLEDGE.md å†…å®¹
        """
        kb_path = "KNOWLEDGE.md"
        if os.path.exists(kb_path):
            with open(kb_path, "r", encoding="utf-8") as f:
                print(f"ğŸ“š å·²åŠ è½½å¤–éƒ¨çŸ¥è¯†åº“: {kb_path}")
                return f.read()
        else:
            print("âš ï¸ æœªæ‰¾åˆ°çŸ¥è¯†åº“æ–‡ä»¶ KNOWLEDGE.md")
            return "æš‚æ— å¤–éƒ¨çŸ¥è¯†åº“ã€‚"

    def log(self, message):
        print(f"[{datetime.now().strftime('%H:%M:%S')}] {message}")

    def run(self, product_brief: str):
        self.log(f"ğŸš€ å¯åŠ¨ AI è®¾è®¡å·¥ä½œæµï¼Œç›®æ ‡ä»»åŠ¡: {product_brief}")

        try:
            # Step 1: å¸‚åœºä¸ç«å“åˆ†æ
            self.log("ğŸ” Agent 1 (Market Analyst) æ­£åœ¨è¿›è¡Œå¸‚åœºè¶‹åŠ¿åˆ†æ...")
            market_analysis, _ = self.step_market_analysis(product_brief)
            self.log("âœ… å¸‚åœºåˆ†æå®Œæˆ")
            self._save_intermediate("1_Market_Analysis.md", market_analysis)

            # Step 2: è§†è§‰å‚è€ƒä¸ç—›ç‚¹æŒ–æ˜
            self.log("ğŸ¨ Agent 2 (Visual Researcher) æ­£åœ¨å¯»æ‰¾è§†è§‰å‚è€ƒå¹¶åˆ†æç—›ç‚¹...")
            visual_research, _ = self.step_visual_research(
                product_brief, market_analysis
            )
            self.log("âœ… è§†è§‰è°ƒç ”å®Œæˆ")
            self._save_intermediate("2_Visual_Research.md", visual_research)

            # Step 3: æ–¹æ¡ˆç”Ÿæˆä¸ Prompt è¾“å‡º
            self.log("ğŸ’¡ Agent 3 (Product Designer) æ­£åœ¨æ„æ€è®¾è®¡æ–¹æ¡ˆä¸ç»˜å›¾ Prompt...")
            design_proposals, design_prompts = self.step_design_generation(
                product_brief, market_analysis, visual_research
            )
            self.log("âœ… è®¾è®¡æ–¹æ¡ˆç”Ÿæˆå®Œæˆ")
            self._save_intermediate("3_Design_Proposals.md", design_proposals)

            # Step 4: è°ƒç”¨å³æ¢¦ç”Ÿæˆå›¾ç‰‡
            self.log("ğŸ¨ Agent 4 (Image Generator) æ­£åœ¨æ ¹æ®æ–¹æ¡ˆç”Ÿæˆæ¦‚å¿µå›¾...")
            self.step_image_generation(design_prompts)
            self.log("âœ… å›¾ç‰‡ç”Ÿæˆå®Œæˆ")

            # Step 5: ç”ŸæˆæŠ¥å‘Šï¼ˆé‡æ–°è¯»å–åŒ…å«å›¾ç‰‡è·¯å¾„çš„ JSONï¼‰
            self.log("ğŸ“ æ­£åœ¨ç”Ÿæˆæœ€ç»ˆè®¾è®¡æŠ¥å‘Š...")
            # é‡æ–°è¯»å–æ›´æ–°åçš„ JSONï¼ˆåŒ…å« image_pathï¼‰
            json_path = os.path.join(self.output_dir, "3_Design_Proposals.json")
            if os.path.exists(json_path):
                with open(json_path, "r", encoding="utf-8") as f:
                    updated_design_data = json.load(f)
                # è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²ï¼Œä¸ step_design_generation çš„è¿”å›æ ¼å¼ä¸€è‡´
                design_proposals_with_images = json.dumps(updated_design_data, ensure_ascii=False)
            else:
                # å¦‚æœ JSON ä¸å­˜åœ¨ï¼Œä½¿ç”¨åŸå§‹æ•°æ®
                design_proposals_with_images = design_proposals

            report_path = self._save_report(
                product_brief, market_analysis, visual_research, design_proposals_with_images
            )
            self.log(f"ğŸ“„ å®Œæ•´è®¾è®¡æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")

        except MarketAnalysisError as e:
            self.log(f"âŒ å¸‚åœºåˆ†æå¤±è´¥: {e.message}")
            raise
        except VisualResearchError as e:
            self.log(f"âŒ è§†è§‰ç ”ç©¶å¤±è´¥: {e.message}")
            raise
        except DesignGenerationError as e:
            self.log(f"âŒ æ–¹æ¡ˆè®¾è®¡å¤±è´¥: {e.message}")
            raise
        except ImageGenerationError as e:
            self.log(f"âŒ å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {e.message}")
            raise
        except Exception as e:
            self.log(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
            raise DesignWorkflowError(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}", recoverable=False)

    def _get_prompt(self, agent_name, default_template, **kwargs):
        """
        è·å– Promptï¼Œä¼˜å…ˆä½¿ç”¨ CONFIG.md ä¸­çš„é…ç½®
        """
        prompts = self.custom_config.get("prompts", {})
        template = prompts.get(agent_name, default_template)

        # è‡ªåŠ¨æ³¨å…¥ knowledge å‚æ•°ï¼Œå¦‚æœæ¨¡æ¿ä¸­æœ‰ {knowledge} å ä½ç¬¦
        if "{knowledge}" in template and "knowledge" not in kwargs:
            kwargs["knowledge"] = self.knowledge_base

        try:
            return template.format(**kwargs)
        except KeyError as e:
            self.log(f"âš ï¸ Prompt æ¨¡æ¿å‚æ•°ç¼ºå¤±: {e}ï¼Œå°†ä½¿ç”¨é»˜è®¤æ¨¡æ¿")
            return default_template.format(**kwargs)

    def _process_llm_json_response(
        self, raw_response: str
    ) -> Tuple[str, List[Dict], Dict]:
        """
        è§£æ LLM çš„ JSON å“åº”ï¼Œç”Ÿæˆæ’å›¾ï¼Œå¹¶è¿”å›æ ¼å¼åŒ–çš„ Markdownã€æ•°æ®åˆ—è¡¨å’ŒåŸå§‹æ•°æ®
        """
        try:
            # å°è¯•æå– JSON å—
            json_str = raw_response
            match = re.search(r"```json\s*(.*?)```", raw_response, re.DOTALL)
            if match:
                json_str = match.group(1)
            else:
                # å°è¯•æŸ¥æ‰¾ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª }
                match = re.search(r"\{.*\}", raw_response, re.DOTALL)
                if match:
                    json_str = match.group(0)

            # æ¸…ç† JSON å­—ç¬¦ä¸²ä¸­çš„æ§åˆ¶å­—ç¬¦
            json_str = re.sub(r"[\x00-\x1f\x7f-\x9f]", "", json_str)
            # å¤„ç†è½¬ä¹‰å­—ç¬¦é—®é¢˜
            json_str = json_str.replace("\\n", " ").replace("\\r", " ")

            data = json.loads(json_str)

            summary = data.get("summary", "")
            content = data.get("content", "")
            visuals = data.get("visuals", [])
            prompts = data.get("prompts", [])  # For step 3

            # 1. ç»„åˆ Summary
            final_content = ""
            if summary:
                final_content += f"> ğŸ’¡ **æ ¸å¿ƒæ‘˜è¦**: {summary}\n\n"

            # 2. ç”Ÿæˆå¹¶æ’å…¥æ’å›¾ (Visuals)
            if visuals:
                self.log(f"    - æ£€æµ‹åˆ° {len(visuals)} ä¸ªå¯è§†åŒ–æ¦‚å¿µï¼Œå‡†å¤‡ç”Ÿæˆæ’å›¾...")
                for item in visuals:
                    concept = item.get("concept", "Concept")
                    prompt = item.get("prompt", "")
                    if prompt:
                        self.log(f"      -> ç”Ÿæˆæ’å›¾: {concept}...")
                        img_path = self.image_gen.generate_image(
                            prompt, self.output_dir
                        )
                        if img_path:
                            # ä¿®å¤ï¼šå¦‚æœæ˜¯ Supabase URLï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦‚æœæ˜¯æœ¬åœ°è·¯å¾„ï¼Œæ‰è®¡ç®—ç›¸å¯¹è·¯å¾„
                            if img_path.startswith("http"):
                                img_url = img_path
                            else:
                                img_url = os.path.relpath(img_path, self.output_dir)

                            final_content += (
                                f"\n![{concept}]({img_url})\n*å›¾ç¤ºï¼š{concept}*\n"
                            )
                            self.generated_images.append(img_path)
                            # ä¿®å¤ï¼šç¡®ä¿ç›´æ¥ä¿å­˜ Supabase URLï¼Œè€Œéå¼ºåˆ¶è½¬æ¢ä¸ºæŸåçš„æœ¬åœ°è·¯å¾„
                            if img_path.startswith("http"):
                                item["image_path"] = img_path
                            else:
                                item["image_path"] = (
                                    f"/projects/{os.path.basename(self.output_dir)}/{os.path.basename(img_path)}"
                                )

            final_content += content

            return final_content, prompts if prompts else visuals, data

        except json.JSONDecodeError as e:
            self.log(f"âš ï¸ JSON è§£æé”™è¯¯: {e}")
            raise DesignGenerationError(f"æ— æ³•è§£æ LLM çš„ JSON å“åº”: {e}")
        except Exception as e:
            self.log(f"âš ï¸ å¤„ç†å“åº”æ—¶å‡ºé”™: {e}")
            raise DesignGenerationError(f"å¤„ç†å“åº”æ—¶å‡ºé”™: {e}")

    def step_market_analysis(self, brief, stream=False) -> Tuple[str, List]:
        default_prompt = "è¯·è¾“å‡º JSON æ ¼å¼çš„å¸‚åœºåˆ†æã€‚"  # Fallback
        prompt = self._get_prompt(
            "market_analyst", default_prompt, brief=brief, knowledge=self.knowledge_base
        )
        messages = [{"role": "user", "content": prompt}]

        if stream:
            return self.llm.chat_completion_stream(messages)

        response = self.llm.chat_completion(messages)
        try:
            md, prompts, data = self._process_llm_json_response(response)
        except DesignGenerationError:
            # å¦‚æœ JSON è§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å“åº”
            md = response
            prompts = []
            data = {}

        # ä¿å­˜ JSON åŸå§‹æ•°æ®
        if data:
            self._save_intermediate(
                "1_Market_Analysis.json", json.dumps(data, ensure_ascii=False, indent=2)
            )
        return md, prompts

    def step_visual_research(
        self, brief, market_analysis, stream=False
    ) -> Tuple[str, List]:
        default_prompt = "è¯·è¾“å‡º JSON æ ¼å¼çš„è§†è§‰è°ƒç ”ã€‚"  # Fallback
        prompt = self._get_prompt(
            "visual_researcher",
            default_prompt,
            brief=brief,
            market_analysis=market_analysis,
            knowledge=self.knowledge_base,
        )
        messages = [{"role": "user", "content": prompt}]

        if stream:
            return self.llm.chat_completion_stream(messages)

        response = self.llm.chat_completion(messages)
        try:
            md, prompts, data = self._process_llm_json_response(response)
        except DesignGenerationError:
            md = response
            prompts = []
            data = {}

        if data:
            self._save_intermediate(
                "2_Visual_Research.json", json.dumps(data, ensure_ascii=False, indent=2)
            )
        return md, prompts

    def step_design_generation(
        self,
        brief,
        market_analysis,
        visual_research,
        image_count=4,
        persona="",
        stream=False,
    ) -> Tuple[str, List]:
        default_prompt = "è¯·è¾“å‡º JSON æ ¼å¼çš„è®¾è®¡æ–¹æ¡ˆã€‚"  # Fallback

        # æ„é€  Persona æŒ‡ä»¤
        persona_instruction = ""
        if persona:
            persona_instruction = f"\nç‰¹åˆ«æ³¨æ„ï¼šè¯·ä»¥ã€{persona}ã€‘çš„ä¸“ä¸šè§†è§’è¿›è¡Œè®¾è®¡æ„æ€ã€‚åœ¨æè¿°æ–¹æ¡ˆç»†èŠ‚æ—¶ï¼Œé‡ç‚¹å…³æ³¨è¯¥è§’è‰²é‡è§†çš„é¢†åŸŸï¼ˆå¦‚æè´¨ã€ç»“æ„ã€å…‰å½±æˆ–åœºæ™¯æ°›å›´ç­‰ï¼‰ã€‚\n"

        # æ„é€ æ•°é‡æŒ‡ä»¤
        count_instruction = f"\nè¯·ç”Ÿæˆ {image_count} ä¸ªä¸åŒçš„è®¾è®¡æ–¹æ¡ˆ/Promptã€‚"

        # è·å–åŸºç¡€ Prompt
        base_prompt = self._get_prompt(
            "product_designer",
            default_prompt,
            brief=brief,
            market_analysis=market_analysis,
            visual_research=visual_research,
            knowledge=self.knowledge_base,
            image_count=image_count,
        )

        # æ‹¼æ¥å®Œæ•´ Prompt
        full_prompt = base_prompt + persona_instruction

        messages = [{"role": "user", "content": full_prompt}]

        if stream:
            return self.llm.chat_completion_stream(messages)

        response = self.llm.chat_completion(messages)
        try:
            md, prompts, data = self._process_llm_json_response(response)
        except DesignGenerationError:
            md = response
            prompts = []
            data = {}

        if data:
            self._save_intermediate(
                "3_Design_Proposals.json",
                json.dumps(data, ensure_ascii=False, indent=2),
            )
            # Return JSON string instead of markdown to allow frontend to render rich card view
            return json.dumps(data, ensure_ascii=False), prompts
        return md, prompts

    def step_image_generation(
        self, prompts_list: List[Dict], session_id=None, skip_json_update=False
    ):
        """
        æ ¹æ® Prompts åˆ—è¡¨ç”Ÿæˆå›¾ç‰‡ (å¹¶è¡Œ)ï¼Œå¹¶æ›´æ–°å¯¹åº”çš„ JSON æ–‡ä»¶å’Œæ•°æ®åº“
        """
        if not prompts_list:
            self.log("    âš ï¸ æœªæ£€æµ‹åˆ°æœ‰æ•ˆ Promptï¼Œè·³è¿‡ç»˜å›¾ã€‚")
            return

        # æå–æœ‰æ•ˆ prompt åŠå…¶ç´¢å¼•
        valid_tasks = []  # (index, prompt_text)
        for i, item in enumerate(prompts_list):
            p = item.get("prompt", "")
            if p:
                valid_tasks.append((i, p))

        if not valid_tasks:
            return

        total = len(valid_tasks)
        self.log(
            f"    - å‡†å¤‡å¹¶è¡Œç”Ÿæˆ {total} å¼ æ–¹æ¡ˆå›¾ (SessionID: {'Yes' if session_id else 'No'})..."
        )

        def generate_single(p):
            try:
                return self.image_gen.generate_image(
                    p, self.output_dir, session_id=session_id
                )
            except Exception as e:
                self.log(f"Error generating image: {e}")
                return None

        # è·å–æœ€å¤§å¹¶å‘æ•°
        max_workers = getattr(config, "MAX_CONCURRENT_IMAGES", 3)
        max_workers = min(max_workers, len(valid_tasks))

        # ä½¿ç”¨ future æ˜ å°„æ¥ä¿æŒç»“æœä¸åŸå§‹åˆ—è¡¨çš„å¯¹åº”å…³ç³»
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # map future to index
            future_to_index = {
                executor.submit(generate_single, p): idx for idx, p in valid_tasks
            }

            for future in concurrent.futures.as_completed(future_to_index):
                idx = future_to_index[future]
                try:
                    img_path = future.result()
                    if img_path:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯ Supabase Storage URL
                        if img_path.startswith("http"):
                            # ä½¿ç”¨ Supabase Storage URL
                            self.log(f"      -> å›¾ç‰‡å·²ä¿å­˜åˆ°äº‘ç«¯: {img_path[:80]}...")
                            self.generated_images.append(img_path)
                            prompts_list[idx]["image_path"] = img_path
                        else:
                            # æœ¬åœ°è·¯å¾„ï¼Œæ„å»ºç›¸å¯¹è·¯å¾„
                            self.log(
                                f"      -> å›¾ç‰‡å·²ä¿å­˜: {os.path.basename(img_path)}"
                            )
                            self.generated_images.append(img_path)
                            rel_path = f"/projects/{os.path.basename(self.output_dir)}/{os.path.basename(img_path)}"
                            prompts_list[idx]["image_path"] = rel_path
                except Exception as e:
                    self.log(f"      -> ç”Ÿæˆå¤±è´¥ (Index {idx}): {e}")

        if skip_json_update:
            return

        # å°è¯•æ›´æ–° 3_Design_Proposals.json å’Œæ•°æ®åº“
        json_path = os.path.join(self.output_dir, "3_Design_Proposals.json")
        updated_data = None

        if os.path.exists(json_path):
            try:
                with open(json_path, "r", encoding="utf-8") as f:
                    data = json.load(f)

                # æ›´æ–° data ä¸­çš„ prompts
                # æ³¨æ„ï¼šprompts_list æ˜¯ä» data['prompts'] æå–å‡ºæ¥çš„ï¼Œå¼•ç”¨å¯èƒ½å·²æ–­å¼€ï¼ˆå¦‚æœç»è¿‡äº†åºåˆ—åŒ–/ååºåˆ—åŒ–ï¼‰
                # ä½†åœ¨è¿™é‡Œæˆ‘ä»¬ç›´æ¥ä¿®æ”¹äº† data ä¸­çš„å¯¹åº”ç»“æ„ï¼Œå› ä¸ºæˆ‘ä»¬çŸ¥é“ç»“æ„æ˜¯ {'prompts': [...]}
                if "prompts" in data and isinstance(data["prompts"], list):
                    # æŒ‰ç…§ç´¢å¼•åˆå¹¶ image_path
                    for i, item in enumerate(prompts_list):
                        if i < len(data["prompts"]):
                            if "image_path" in item:
                                data["prompts"][i]["image_path"] = item["image_path"]

                # å›å†™æ–‡ä»¶
                with open(json_path, "w", encoding="utf-8") as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                self.log("âœ… å·²æ›´æ–° Design Proposals JSON æ–‡ä»¶ä¸­çš„å›¾ç‰‡è·¯å¾„")

                updated_data = data

            except Exception as e:
                self.log(f"âš ï¸ æ›´æ–° JSON æ–‡ä»¶å¤±è´¥: {e}")

        # åŒæ­¥åˆ°æ•°æ®åº“
        try:
            # ä½¿ç”¨å±€éƒ¨å¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
            from . import api as api_module

            # è·å–æ•°æ®åº“ä¸­çš„ç°æœ‰å†…å®¹
            db_proj = api_module.db_get_project(os.path.basename(self.output_dir))
            existing_content = db_proj.get("content", {}) if db_proj else {}

            # æ›´æ–° design_proposals å­—æ®µ
            if updated_data:
                existing_content["design_proposals"] = json.dumps(
                    updated_data, ensure_ascii=False, indent=2
                )
            else:
                # å³ä½¿ JSON æ–‡ä»¶æ›´æ–°å¤±è´¥ï¼Œä¹Ÿå°è¯•åŒæ­¥ prompts_list ä¸­çš„ image_path
                if "design_proposals" in existing_content:
                    try:
                        existing_proposals = json.loads(
                            existing_content["design_proposals"]
                        )
                        if "prompts" in existing_proposals:
                            for i, item in enumerate(prompts_list):
                                if (
                                    i < len(existing_proposals["prompts"])
                                    and "image_path" in item
                                ):
                                    existing_proposals["prompts"][i]["image_path"] = (
                                        item["image_path"]
                                    )
                            existing_content["design_proposals"] = json.dumps(
                                existing_proposals, ensure_ascii=False, indent=2
                            )
                    except (json.JSONDecodeError, KeyError):
                        pass

            # ä¿å­˜åˆ°æ•°æ®åº“
            api_module.save_project_content(
                os.path.basename(self.output_dir), existing_content
            )
            self.log("âœ… å·²åŒæ­¥å›¾ç‰‡è·¯å¾„åˆ°æ•°æ®åº“")

            # ä¿å­˜å›¾ç‰‡åˆ—è¡¨åˆ°æ•°æ®åº“
            if self.generated_images:
                # æ„å»ºå‰ç«¯å¯è®¿é—®çš„å›¾ç‰‡è·¯å¾„
                # æ³¨æ„ï¼šå¦‚æœæ˜¯ Supabase URLï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦‚æœæ˜¯æœ¬åœ°è·¯å¾„ï¼Œæ„å»ºç›¸å¯¹è·¯å¾„
                image_paths = []
                for p in self.generated_images:
                    if p.startswith("http"):
                        # Supabase Storage URLï¼Œç›´æ¥ä½¿ç”¨
                        image_paths.append(p)
                    else:
                        # æœ¬åœ°è·¯å¾„ï¼Œæ„å»ºç›¸å¯¹è·¯å¾„
                        image_paths.append(
                            f"/projects/{os.path.basename(self.output_dir)}/{os.path.basename(p)}"
                        )
                api_module.save_project_images(
                    os.path.basename(self.output_dir), image_paths
                )
                self.log("âœ… å·²ä¿å­˜å›¾ç‰‡åˆ—è¡¨åˆ°æ•°æ®åº“")

        except Exception as e:
            self.log(f"âš ï¸ åŒæ­¥æ•°æ®åº“å¤±è´¥: {e}")

    # ä¿ç•™æ—§çš„å†…éƒ¨æ–¹æ³•åä»¥å…¼å®¹ï¼ˆå¦‚æœæœ‰å…¶ä»–åœ°æ–¹è°ƒç”¨ï¼‰ï¼Œä½†æŒ‡å‘æ–°æ–¹æ³•
    _step_market_analysis = step_market_analysis
    _step_visual_research = step_visual_research
    _step_design_generation = step_design_generation

    # æ—§çš„ _step_image_generation é€»è¾‘ä¸å†é€‚ç”¨æ–°çš„ JSON ç»“æ„ï¼Œ
    # ä½†ä¸ºäº†å…¼å®¹ web_app å¯èƒ½çš„è°ƒç”¨ï¼Œæˆ‘ä»¬éœ€è¦ä¿ç•™ä¸€ä¸ªé€‚é…å™¨
    def _step_image_generation(self, design_proposals):
        # å¦‚æœ web_app è¿˜åœ¨ä¼ æ–‡æœ¬è¿›æ¥ï¼Œæˆ‘ä»¬å°è¯•ç”¨æ—§é€»è¾‘æ­£åˆ™æå–?
        # æˆ–è€… web_app åº”è¯¥æ›´æ–°ä¸ºä¼ é€’ prompts_list
        # è¿™é‡Œå…ˆä¿ç•™æ—§é€»è¾‘ä½œä¸º fallbackï¼Œæˆ–è€…æ‰“å°è­¦å‘Š
        pass

    def _save_intermediate(self, filename, content):
        # å®‰å…¨æ–‡ä»¶å
        safe_filename = "".join(
            [
                c
                for c in filename
                if c.isalpha() or c.isdigit() or c in (" ", "_", "-", ".")
            ]
        ).strip()
        filepath = os.path.join(self.output_dir, safe_filename)
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)

    def _save_report(self, brief, p1, p2, p3):
        filename = f"Full_Design_Report.md"
        filepath = os.path.join(self.output_dir, filename)

        # å¤„ç†ç¬¬ä¸‰é˜¶æ®µçš„å†…å®¹ï¼šå°† JSON è½¬æ¢ä¸ºå¸¦å›¾ç‰‡çš„ Markdown
        p3_content = p3
        try:
            # å°è¯•è§£æ p3 ä½œä¸º JSONï¼ˆå› ä¸º step_design_generation è¿”å› JSON å­—ç¬¦ä¸²ï¼‰
            data = json.loads(p3)
            if isinstance(data, dict) and "prompts" in data:
                # æ„å»ºå¸¦å›¾ç‰‡çš„ Markdown
                p3_content = ""
                if "summary" in data:
                    p3_content += f"> ğŸ’¡ **æ ¸å¿ƒæ‘˜è¦**: {data['summary']}\n\n"

                # æ·»åŠ æ¯ä¸ªè®¾è®¡æ–¹æ¡ˆåŠå…¶å›¾ç‰‡
                for i, prompt_item in enumerate(data["prompts"], 1):
                    scheme = prompt_item.get("scheme", f"æ–¹æ¡ˆ {i}")
                    description = prompt_item.get("description", "")
                    inspiration = prompt_item.get("inspiration", "")
                    image_path = prompt_item.get("image_path", "")

                    p3_content += f"\n### æ–¹æ¡ˆ {i}ï¼š{scheme}\n\n"
                    if inspiration:
                        p3_content += f"**è®¾è®¡çµæ„Ÿï¼š** {inspiration}\n\n"
                    if description:
                        p3_content += f"{description}\n\n"
                    if image_path:
                        # å¤„ç†å›¾ç‰‡è·¯å¾„
                        if image_path.startswith("http"):
                            # Supabase URLï¼Œç›´æ¥ä½¿ç”¨
                            img_url = image_path
                        else:
                            # æœ¬åœ°è·¯å¾„ï¼Œä½¿ç”¨æ–‡ä»¶å
                            img_url = os.path.basename(image_path)
                        p3_content += f"![{scheme}]({img_url})\n\n"
        except (json.JSONDecodeError, ValueError):
            # å¦‚æœä¸æ˜¯ JSONï¼Œä½¿ç”¨åŸå§‹å†…å®¹
            pass

        content = f"""# AI è®¾è®¡å·¥ä½œæµæŠ¥å‘Š

## é¡¹ç›®éœ€æ±‚
{brief}

## ç¬¬ä¸€é˜¶æ®µï¼šå¸‚åœºåˆ†æ
{p1}

## ç¬¬äºŒé˜¶æ®µï¼šè§†è§‰è°ƒç ”ä¸ç—›ç‚¹åˆ†æ
{p2}

## ç¬¬ä¸‰é˜¶æ®µï¼šè®¾è®¡æ–¹æ¡ˆä¸ Prompts
{p3_content}

---
*Generated by AI Design Workflow at {datetime.now()}*
"""
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)
        return filepath


def main():
    # 1. è¯»å–é…ç½®
    config_path = "CONFIG.md"
    custom_config = {}
    if os.path.exists(config_path):
        print(f"ğŸ“– è¯»å–ç³»ç»Ÿé…ç½®: {config_path}")
        custom_config = md_parser.parse_config_md(config_path)
    else:
        print("âš ï¸ æœªæ‰¾åˆ° CONFIG.mdï¼Œä½¿ç”¨é»˜è®¤é…ç½®")

    # 2. è¯»å–éœ€æ±‚
    request_path = "REQUEST.md"
    if len(sys.argv) > 1:
        # æ”¯æŒå‘½ä»¤è¡Œè¦†ç›–
        brief = sys.argv[1]
        project_name = f"manual_run_{int(time.time())}"
    elif os.path.exists(request_path):
        print(f"ğŸ“– è¯»å–ç”¨æˆ·éœ€æ±‚: {request_path}")
        req_data = md_parser.parse_request_md(request_path)
        brief = req_data["description"]
        project_name = req_data["project_name"]

        if not brief:
            print("âŒ é”™è¯¯: REQUEST.md ä¸­æœªæ‰¾åˆ°è¯¦ç»†éœ€æ±‚æè¿°ã€‚")
            return
    else:
        print("è¯·è¾“å…¥è®¾è®¡éœ€æ±‚ (ä¾‹å¦‚: 'è®¾è®¡ä¸€æ¬¾ä¸­é«˜ç«¯çš„å®æœ¨ç›¸æ¡†')")
        brief = input("> ")
        project_name = f"manual_run_{int(time.time())}"

    # 3. åˆ›å»ºé¡¹ç›®æ–‡ä»¶å¤¹
    # å¤„ç†ä¸åˆæ³•çš„æ–‡ä»¶åå­—ç¬¦
    safe_project_name = "".join(
        [c for c in project_name if c.isalpha() or c.isdigit() or c in (" ", "_", "-")]
    ).strip()
    safe_project_name = safe_project_name.replace(" ", "_")

    project_dir = os.path.join("projects", safe_project_name)
    if not os.path.exists(project_dir):
        os.makedirs(project_dir)
        print(f"ğŸ“‚ åˆ›å»ºé¡¹ç›®æ–‡ä»¶å¤¹: {project_dir}")
    else:
        print(f"ğŸ“‚ ä½¿ç”¨å·²æœ‰é¡¹ç›®æ–‡ä»¶å¤¹: {project_dir}")

    # 4. è¿è¡Œå·¥ä½œæµ
    workflow = DesignWorkflow(output_dir=project_dir, custom_config=custom_config)
    workflow.run(brief)


if __name__ == "__main__":
    main()
